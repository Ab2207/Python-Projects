{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0132da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811681a7",
   "metadata": {},
   "source": [
    "#### This function takes position and location of job as the input parameters and creates a URL with an appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29bb5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position, location):\n",
    "    \n",
    "    template = \"https://ie.indeed.com/jobs?q={}&l={}\"\n",
    "    position = position.replace(' ', \"+\")\n",
    "    location = location.replace(' ', \"+\")\n",
    "    url = template.format(position, location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff11372",
   "metadata": {},
   "source": [
    "#### This function's job is to scrape the information of each job card and save it in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc5f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(card):\n",
    "    \n",
    "    atag = card.h2.a\n",
    "    job_title = atag.get('title')\n",
    "    job_url = 'https://ie.indeed.com' + atag.get('href')\n",
    "    company = card.find('span', 'company').text.strip()\n",
    "    location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
    "    summary = card.find('div', 'summary').text.strip().replace(\"\\n\", ' ')\n",
    "    post_date = card.find('span', 'date').text\n",
    "    \n",
    "    record = (job_title, company, location, summary, post_date, job_url)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48c76c",
   "metadata": {},
   "source": [
    "#### This is the main function where the URL is accessed and parsed with the help of BeautifulSoup. \n",
    "#### Once the records in the first page is scraped, the try-except block will check if there is a next page available. While this condition is True, the function continues. \n",
    "#### Finally, a CSV file is opened and all the records are written into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e680fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(position, location):\n",
    "    \n",
    "    records = []\n",
    "    url = get_url(position, location)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        r = requests.get(url) \n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n",
    "        for card in cards:\n",
    "            record = get_records(card)\n",
    "            records.append(record)\n",
    "        \n",
    "        try:\n",
    "            url='https://ie.indeed.com' + soup.find('a', {'aria-label':'Next'}).get('href')\n",
    "        \n",
    "        except:\n",
    "            break\n",
    "\n",
    "        with open('job_postings.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['JobTitle', 'Company', 'Location', 'Summary', 'Post Date', 'Job URL'])\n",
    "            writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630dc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main('data analyst', 'dublin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
